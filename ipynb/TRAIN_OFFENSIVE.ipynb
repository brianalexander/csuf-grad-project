{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TRAIN_OFFENSIVE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpA1bOds0aIz",
        "outputId": "4ea03e35-fa42-41e6-c5bc-2163824f4ff4"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-lightning\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install torchmetrics\n",
        "!pip install ipywidgets\n",
        "!pip install IProgress"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/b9/59ce5be6679884579c276f5f208587c3312e8323bd7ce27be278b7af98b3/pytorch_lightning-1.3.2-py3-none-any.whl (805kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808kB 7.7MB/s \n",
            "\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 50.0MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/14/52/aa227a0884df71ed1957649085adf2b8bc2a1816d037c2f18b3078854516/pyDeprecate-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (20.9)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829kB 51.9MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Collecting fsspec[http]>=2021.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.30.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 50.1MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (21.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=9ffb602372a3e0353ddc2c4942fac791308e6d8d59ae95b65f2a583f94bf7b90\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: PyYAML, pyDeprecate, future, torchmetrics, async-timeout, multidict, yarl, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.5.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.2 torchmetrics-0.3.2 yarl-1.6.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (20.9)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.8.1+cu101)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.3)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.0.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (56.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
            "Collecting IProgress\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/92/46acb3eccee1d0e5581dea18455ebc2d25ec8da77d6c45d395882d4b9dd4/IProgress-0.4-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from IProgress) (1.15.0)\n",
            "Installing collected packages: IProgress\n",
            "Successfully installed IProgress-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45z2fqdffQZ9"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJFTchyfXcZA"
      },
      "source": [
        "# Python\n",
        "import json\n",
        "import os\n",
        "from typing import Optional\n",
        "\n",
        "# General 3rd Party\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# HuggingFace\n",
        "from transformers import BertForSequenceClassification, BertTokenizerFast, BertConfig\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "from torch.functional import F\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, loggers, seed_everything\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "import torchmetrics"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeKxnIjqgqNw",
        "outputId": "47c8b222-b908-48b0-ba6b-1fbd0a655b64"
      },
      "source": [
        "seed_everything(42, workers=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLMoHcIvGR3k",
        "outputId": "677bf2ce-4390-45d9-ee43-b53d2dda9e05"
      },
      "source": [
        "MODEL_DIRECTORY = '/home/brian/Documents/kubernetes/models/offensive'\n",
        "\n",
        "directories_needed = [MODEL_DIRECTORY]\n",
        "\n",
        "input_paths = '/home/brian/Documents/kubernetes/datasets/live/offensive/test_a_labels_all.csv'\n",
        "labels_path = '/home/brian/Documents/kubernetes/datasets/live/offensive/test_a_tweets_all.tsv'\n",
        "\n",
        "\n",
        "files_needed = [input_paths, labels_path]\n",
        "\n",
        "def assertFilesAndDirectoriesExist(files, directories):\n",
        "  for d in directories:\n",
        "    assert os.path.isdir(d)\n",
        "\n",
        "  for f in files:\n",
        "    assert os.path.exists(f)\n",
        "  \n",
        "  print(\"+ All files and directories accounted for!\")\n",
        "\n",
        "assertFilesAndDirectoriesExist(files_needed, directories_needed)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+ All files and directories accounted for!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWzxe_WLQiAc"
      },
      "source": [
        "## Load Data from Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIpBl1LLJVMD"
      },
      "source": [
        "labels_frame = pd.read_csv(input_paths, names=['id', 'label'])\n",
        "inputs_frame = pd.read_csv(labels_path, sep=\"\\t\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "R6brCP954i5R",
        "outputId": "7d223f57-24e2-4a36-a1c4-15dd96ae27d1"
      },
      "source": [
        "inputs_frame.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              tweet\n",
              "0  B0  Has @USER quit? I've not heard of any #knifecr...\n",
              "1  B1  In celebration of Emancipation Day, we urge yo...\n",
              "2  B2  @USER @USER Itâ€™d be a literal dream come true ...\n",
              "3  B3  Brilliant news to read that Hoggy has signed a...\n",
              "4  B4                    @USER She speaks of the truth ðŸ˜Œ"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0</td>\n",
              "      <td>Has @USER quit? I've not heard of any #knifecr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B1</td>\n",
              "      <td>In celebration of Emancipation Day, we urge yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B2</td>\n",
              "      <td>@USER @USER Itâ€™d be a literal dream come true ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B3</td>\n",
              "      <td>Brilliant news to read that Hoggy has signed a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B4</td>\n",
              "      <td>@USER She speaks of the truth ðŸ˜Œ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uHY1pcxMD2el",
        "outputId": "21a0c17a-2b9c-4470-d1f8-f8cabe6679a7"
      },
      "source": [
        "labels_frame.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id label\n",
              "0  BC0   OFF\n",
              "1  BC1   OFF\n",
              "2  BC2   OFF\n",
              "3  BC3   OFF\n",
              "4  BC4   OFF"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BC0</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BC1</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BC2</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BC3</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BC4</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV-ACl6kETk_"
      },
      "source": [
        "labels_frame['label'] = labels_frame['label'].apply(lambda x: 1 if x == 'OFF' else 0)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "57Z_dsUJI8Em",
        "outputId": "8c77b2d0-24bf-49e1-b42c-5a44d8de7b09"
      },
      "source": [
        "inputs_frame.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              tweet\n",
              "0  B0  Has @USER quit? I've not heard of any #knifecr...\n",
              "1  B1  In celebration of Emancipation Day, we urge yo...\n",
              "2  B2  @USER @USER Itâ€™d be a literal dream come true ...\n",
              "3  B3  Brilliant news to read that Hoggy has signed a...\n",
              "4  B4                    @USER She speaks of the truth ðŸ˜Œ"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0</td>\n",
              "      <td>Has @USER quit? I've not heard of any #knifecr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B1</td>\n",
              "      <td>In celebration of Emancipation Day, we urge yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B2</td>\n",
              "      <td>@USER @USER Itâ€™d be a literal dream come true ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B3</td>\n",
              "      <td>Brilliant news to read that Hoggy has signed a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B4</td>\n",
              "      <td>@USER She speaks of the truth ðŸ˜Œ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHj_pI3pEJH4"
      },
      "source": [
        "full_frame = inputs_frame.merge(labels_frame, left_on=\"id\", right_on=\"id\")[['tweet', 'label']].rename(columns={'tweet': 'text'})"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q5FGGF7mI6YC",
        "outputId": "76eab290-67ee-42f1-cf5b-7fb9573b4fcd"
      },
      "source": [
        "full_frame.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Has @USER quit? I've not heard of any #knifecr...      0\n",
              "1  In celebration of Emancipation Day, we urge yo...      0\n",
              "2  @USER @USER Itâ€™d be a literal dream come true ...      0\n",
              "3  Brilliant news to read that Hoggy has signed a...      0\n",
              "4                    @USER She speaks of the truth ðŸ˜Œ      0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Has @USER quit? I've not heard of any #knifecr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In celebration of Emancipation Day, we urge yo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@USER @USER Itâ€™d be a literal dream come true ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brilliant news to read that Hoggy has signed a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@USER She speaks of the truth ðŸ˜Œ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIdJhLpDj9BW"
      },
      "source": [
        "full_frame = full_frame.sample(frac=1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "op87CUpKKkk7",
        "outputId": "c25f453f-b6eb-46f6-f8fc-90b9f77c201c"
      },
      "source": [
        "full_frame.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "2404  @USER One of my favorite songs. Reminds me now...      0\n",
              "1916  @USER HOWWJDJJSKDKS. is it bc he gRew uP LMFOA...      0\n",
              "2503  im tired of not being able to fucking sleep , ...      1\n",
              "2513  I am legit sick of being into women, theyâ€™re T...      1\n",
              "2024  @USER We live riding that. To bad it costs the...      0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2404</th>\n",
              "      <td>@USER One of my favorite songs. Reminds me now...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1916</th>\n",
              "      <td>@USER HOWWJDJJSKDKS. is it bc he gRew uP LMFOA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2503</th>\n",
              "      <td>im tired of not being able to fucking sleep , ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2513</th>\n",
              "      <td>I am legit sick of being into women, theyâ€™re T...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024</th>\n",
              "      <td>@USER We live riding that. To bad it costs the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I01-AxwMAF1"
      },
      "source": [
        "inputs = full_frame['text'].values\n",
        "labels = full_frame['label'].values"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8otF-OnEQ19k"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg92IyPopeV8"
      },
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU6_eSi_EmbM"
      },
      "source": [
        "class TextLabelTokenizerDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"Offensive Language Dataset\"\"\"\n",
        "\n",
        "  def __init__(self, inputs, labels, tokenizer):\n",
        "    super().__init__()\n",
        "\n",
        "    self.inputs = inputs\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    encoding = self.tokenizer(\n",
        "        self.inputs[idx],\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=500\n",
        "    )\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "    \n",
        "    return {\n",
        "        \"input_ids\": input_ids.type(torch.long),\n",
        "        \"attention_mask\": attention_mask.type(torch.long),\n",
        "        \"target\": torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "    }"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMxan7eRNHhQ"
      },
      "source": [
        "text_label_tokenizer_dataset = TextLabelTokenizerDataset(inputs, labels, tokenizer)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TMAhzlvB3xC"
      },
      "source": [
        "class CustomDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, dataset, batch_size: int = 32):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def prepare_data(self):\n",
        "    # download\n",
        "    pass\n",
        "\n",
        "  def setup(self, stage: Optional[str] = None):\n",
        "    print(\"DATA MODULE SETUP\")\n",
        "    train_size = int(0.6 * len(self.dataset))\n",
        "    val_size = int(0.2 * len(self.dataset))\n",
        "    test_size = len(self.dataset) - train_size - val_size\n",
        "\n",
        "    self.train, self.val, self.test = random_split(\n",
        "        self.dataset, \n",
        "        [train_size, val_size, test_size]\n",
        "        )\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      return DataLoader(self.train, batch_size=self.batch_size, num_workers=16, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "      return DataLoader(self.val, batch_size=self.batch_size, num_workers=16)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "      return DataLoader(self.test, batch_size=self.batch_size, num_workers=16)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUu-kJGalZlJ"
      },
      "source": [
        "custom_datamodule = CustomDataModule(text_label_tokenizer_dataset, batch_size=16)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0YT3WszSXxV"
      },
      "source": [
        "# Model Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqU1iOmjehcw"
      },
      "source": [
        "class BertForSequenceClassificationLM(pl.LightningModule):\n",
        "  def __init__(self, pretrained='bert-base-uncased', bert_weights=None, freeze=True, lr=3e-5, eps=1e-5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.lr = lr\n",
        "    self.eps = eps\n",
        "\n",
        "    config = BertConfig.from_pretrained(pretrained)\n",
        "    config.num_labels = 1\n",
        "\n",
        "    self.classifier = BertForSequenceClassification(\n",
        "        config\n",
        "        )\n",
        "    \n",
        "    if (bert_weights):\n",
        "      weights = torch.load(bert_weights)\n",
        "      self.classifier.bert = weights\n",
        "\n",
        "    if (freeze):    \n",
        "      for param in self.classifier.bert.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    self.train_loss = []\n",
        "    self.val_loss = []\n",
        "    self.val_acc = []\n",
        "    self.test_loss = []\n",
        "    self.test_acc = []\n",
        "\n",
        "    self.loss = F.binary_cross_entropy_with_logits\n",
        "\n",
        "    self.validation_accuracy = torchmetrics.Accuracy()\n",
        "    self.test_accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    return self.classifier(\n",
        "        input_ids=input_ids, \n",
        "        attention_mask=attention_mask, \n",
        "        return_dict=True\n",
        "        )['logits']\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    b_input_ids = batch['input_ids'].view(batch['input_ids'].shape[0], -1)\n",
        "    b_attention_masks = batch[\"attention_mask\"].view(batch['attention_mask'].shape[0], -1)\n",
        "    b_targets = batch[\"target\"].unsqueeze(1)\n",
        "\n",
        "    logits = self(b_input_ids, b_attention_masks)\n",
        "\n",
        "    loss = self.loss(logits, b_targets)\n",
        "\n",
        "    self.log('train_loss', loss, on_step=True, on_epoch=True, \n",
        "             prog_bar=True)\n",
        "\n",
        "    return {'loss': loss}\n",
        "  \n",
        "  def training_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "\n",
        "    self.log(f'epoch_train_loss_{self.current_epoch}', avg_loss)\n",
        "    self.train_loss.append(avg_loss)\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    b_input_ids = batch['input_ids'].view(batch['input_ids'].shape[0], -1)\n",
        "    b_attention_masks = batch[\"attention_mask\"].view(batch['attention_mask'].shape[0], -1)\n",
        "    b_targets = batch[\"target\"].unsqueeze(1)\n",
        "\n",
        "    logits = self(b_input_ids, b_attention_masks)\n",
        "\n",
        "    preds = torch.sigmoid(logits)\n",
        "\n",
        "    val_acc = torch.mean(((preds > 0.5) == b_targets).to(torch.float))\n",
        "    val_loss = self.loss(logits, b_targets)\n",
        "\n",
        "    logs = {'val_loss': val_loss, 'val_acc': val_acc}\n",
        "\n",
        "    self.log('val_loss', val_loss, on_step=True, on_epoch=True, \n",
        "             prog_bar=True)\n",
        "    \n",
        "    return logs\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "    avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
        "\n",
        "    self.log(f'epoch_val_accuracy', avg_acc, on_epoch=True, prog_bar=True)\n",
        "    self.log(f'epoch_val_loss', avg_loss, on_epoch=True, prog_bar=True)\n",
        "    print(\"val_acc\", avg_acc)\n",
        "    print(\"val_loss\", avg_loss)\n",
        "    \n",
        "    self.val_acc.append(avg_acc)\n",
        "    self.val_loss.append(avg_loss)\n",
        "  \n",
        "  def test_step(self, batch, batch_idx):\n",
        "    b_input_ids = batch['input_ids'].view(batch['input_ids'].shape[0], -1)\n",
        "    b_attention_masks = batch[\"attention_mask\"].view(batch['attention_mask'].shape[0], -1)\n",
        "    b_targets = batch[\"target\"].unsqueeze(1)\n",
        "\n",
        "    logits = self(b_input_ids, b_attention_masks)\n",
        "\n",
        "    preds = torch.sigmoid(logits)\n",
        "\n",
        "    test_acc = torch.mean(((preds > 0.5) == b_targets).to(torch.float))\n",
        "    test_loss = self.loss(logits, b_targets)\n",
        "\n",
        "    logs = {'test_loss': test_loss, 'test_acc': test_acc}\n",
        " \n",
        "    self.log('test_loss', test_loss, on_step=True, on_epoch=True, \n",
        "             prog_bar=True)\n",
        "    \n",
        "    return logs\n",
        "  \n",
        "  def test_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
        "    avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
        "\n",
        "    self.log(f'epoch_test_accuracy', avg_acc, on_epoch=True, prog_bar=True)\n",
        "    self.log(f'epoch_test_loss', avg_loss, on_epoch=True, prog_bar=True)\n",
        "    \n",
        "    self.test_acc.append(avg_acc)\n",
        "    self.test_loss.append(avg_loss)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = AdamW(self.parameters(), lr=self.lr, eps=self.eps)\n",
        "\n",
        "    return [optimizer]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsBnwb8RUHoY"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq9LDFHnVqNg",
        "outputId": "937f97eb-1738-445b-dc33-d7790b63dbd9"
      },
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='epoch_val_accuracy',\n",
        "    dirpath=MODEL_DIRECTORY,\n",
        "    filename='offensive-{epoch:02d}-{epoch_val_accuracy:.6f}',\n",
        "    save_top_k=1,\n",
        "    mode='max',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/brian/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Checkpoint directory /home/brian/Documents/kubernetes/models/offensive exists and is not empty.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crvQcbpgkv3b",
        "outputId": "e2077aee-5b5c-406c-c004-91887988c20a"
      },
      "source": [
        "EPOCHS = 4\n",
        "trainer = Trainer(gpus=1, max_epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkIHQKtekv06"
      },
      "source": [
        "model = BertForSequenceClassificationLM(bert_weights=\"/home/brian/Documents/kubernetes/models/base.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEUMH4VY-IVr",
        "outputId": "316aa62f-db69-487b-a2db-3859703cc97f"
      },
      "source": [
        "model.train(mode=True)\n",
        "print(\"setting training mode...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting training mode...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9QnFXg53MM5"
      },
      "source": [
        "trainer.fit(model,custom_datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBev8JC3q2_0"
      },
      "source": [
        "trainer.test(model, datamodule=custom_datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRzipXeyDaGE"
      },
      "source": [
        "# torch.save(model, MODEL_DIRECTORY+\"/offensive.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}